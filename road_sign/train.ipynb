{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の読み込み\n",
    "# $bash copy_image.sh　実行後のディレクトリ構成\n",
    "# ref: https://qiita.com/ba--shi/items/09f5f2f119ffbd9bb316\n",
    "import os\n",
    "import cv2 # dockerの場合　$apt install libgl1-mesa-dev\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def modify_image(img, width, height):\n",
    "    \"\"\"指定した大きさに収まるように、アスペクト比を固定して、リサイズする。\n",
    "       ref: https://camp.trainocate.co.jp/magazine/python-opencv/\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    aspect = w / h\n",
    "    if width / height >= aspect:\n",
    "        nh = height\n",
    "        nw = round(nh * aspect)\n",
    "    else:\n",
    "        nw = width\n",
    "        nh = round(nw / aspect)\n",
    "\n",
    "    scaled = cv2.resize(img, dsize=(nw, nh))\n",
    "    h_padding = round((height - nh) / 2)\n",
    "    w_padding = round((width - nw) / 2)\n",
    "    dst = cv2.copyMakeBorder(scaled, h_padding, height - nh - h_padding, w_padding, width- nw - w_padding, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    return dst\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "IMAGE_SIZE = 500\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "for dir in os.listdir(BASE_DIR + \"/images\"):\n",
    "    img_dir =  BASE_DIR + \"/images/\" + dir\n",
    "    # フォルダごとにラベル分けする\n",
    "    label = dir\n",
    "    \n",
    "    for file in os.listdir(img_dir):\n",
    "        # 配列label_listに正解ラベルを追加\n",
    "        label_list.append(label)\n",
    "        # 配列image_listに画像の配列データを追加\n",
    "        filepath = img_dir + \"/\" + file\n",
    "        img = cv2.imread(filepath)\n",
    "        image = modify_image(img, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        # cv2.imwrite(f'modifyed/{file}', image)\n",
    "        # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        # plt.show()\n",
    "        # image = img_to_array(img)\n",
    "        image_list.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "X = np.asarray(image_list).astype('float32') / 255.0\n",
    "\n",
    "N_CLASSES = 15\n",
    "Y = np.asarray(label_list)\n",
    "Y = tf.keras.utils.to_categorical(Y, N_CLASSES)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=2, \n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        '/code/road_sign/data/temp/road_sign_sequential_{epoch:03d}_{val_loss:.4f}.h5',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='/code/road_sign/logs',\n",
    "        histogram_freq=1\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = vgg_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(N_CLASSES, activation='softmax')(x)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "model = tf.keras.Model(inputs=vgg_model.input, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose='1', validation_data=(test_x, test_y), callbacks=callbacks)\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose='0')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
